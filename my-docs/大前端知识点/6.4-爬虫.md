---
sidebar_position: 112
---

> Create by **fall** on 06 May 2022
> Recently revised in 25 Apr 2023

## 爬虫

各大搜索引擎会对所有的网页进行爬取，用来向用户提供内容



## 服务器应对爬虫



反制手段：



- 消息头User-Agent:里面有python，即为爬虫，当然，可以同过伪造消息头，欺骗服务器
- 通常来讲，python会通过短时间多次爬取网络内容，检测一定时间内访问次数来防治爬虫，但是这种方式可以防治，也容易误伤真正的用户 ，爬虫也可以隔几次切换ip，防止请求超过阈值
- 增加验证码是防治爬虫相当高效且有用的手段，而如今训练神经网络的门槛越来越低，开源视觉库可以免费使用，或者是更高级的图像降噪和二极化，提高机器识别概率。此时防治爬虫能做的只有添加更多的噪点，增加人和机器的识别难度，这种方法杀敌一万，自损八千。
- 通过检测用户的鼠标移动习惯，自行判断是否是人机操作，实际效果比验证码好

## 参考文章

| 作者 | 链接 |
| ---- | ---- |
|      |      |
|      |      |
|      |      |
|      |      |

